{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28086fca-2cdd-41ac-b7bf-bc1af9f759a2",
   "metadata": {},
   "source": [
    "# Laboratorio: Métodos de búsqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e19abc1-82f0-4f28-9493-468e4227c14f",
   "metadata": {},
   "source": [
    "En las clases anteriores creaste códigos para realizar búsquedas aleatorias (Simulated Annealing) y búsquedas dirigidas (Optimización Bayesiana). Estos métodos de búsqueda se utilizan para facilitar el proceso de optimización de funciones objetivos compleja y costosas de computar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038474ce-6e2f-4d45-895a-bb17f7c8871d",
   "metadata": {},
   "source": [
    "En este laboratorio usaremos el dataset de los diferentes tipos de iris, y sus longitudes y anchos de pétalos y sépalos. Utilizaremos un RandomForest para crear un modelo de clasificación y el métrico F1 para decidir cuál es el mejor modelo de acuerdo a lo que tenemos disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04956ea-14f4-419e-adf8-add3b81da443",
   "metadata": {},
   "source": [
    "1. Carga el dataset de Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "aad912f2-1359-437e-af68-3c8cca8d1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X, y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b97ad91-d82b-491c-ac5d-be6f872c5334",
   "metadata": {},
   "source": [
    "2. Importa el archivo `Bosque.py`.\n",
    "\n",
    "Este archivo contiene la función `RegresionBosque`, que recibe:\n",
    "- X: las características independientes\n",
    "- y: la variable de respuesta\n",
    "- árboles: cantidad total de árboles\n",
    "- profundidad de bosque: niveles de profundidad del bosque\n",
    "\n",
    "Su salida es:\n",
    "- modelo: El objeto con el modelo ajustado\n",
    "- f1: El métrico que califica qué tan bueno es el modelo que se ajustó.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "23f875f1-a72a-4a57-8355-16d6bb9fb33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Bosque\n",
    "modelo, f1 = Bosque.RegresionBosque(X, y, 10, 3)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac2825-33ac-4919-9ccb-8324701ce99f",
   "metadata": {},
   "source": [
    "### Actividad 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eb265f-9ccf-4fb4-b8c0-8fe221ea534c",
   "metadata": {},
   "source": [
    "Inicializa un espacio con 5 muestras en nuestro dominio de variables independientes:\n",
    "- árboles: números enteros entre 5 y 50.\n",
    "- profundidad: números enteros entre 2 y 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed7c396-af97-49a6-828e-c5d63c1b6999",
   "metadata": {},
   "source": [
    "Utiliza optimización Bayesiana para encontrar la combinación de árboles y profundidad que **maximice** el métrico F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1e563392-4509-4d70-9cb6-adca944d2406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "modelo, f1 = Bosque.RegresionBosque(X, y, 10, 3)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6b41410b-3f37-46b7-bef3-9361a04b3c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.linspace(0, 2*np.pi, 1000); plt.figure(); y = np.sin(9*x); plt.plot(x, y)\n",
    "# plt.scatter([0, np.pi, 2*np.pi, np.pi/2, 19*np.pi/18], [0, 0, 0, 1, -1], s=50, c=\"r\", zorder=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4af49c74-62b7-45ba-9653-a7e2cd290463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([33, 14, 43,  8, 48]), array([2, 2, 6, 4, 8]))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "num_arboles = np.random.randint(5, 50, 5)\n",
    "nivel_profundidad = np.random.randint(2, 10, 5)\n",
    "\n",
    "num_arboles, nivel_profundidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c7daec29-1479-416f-a003-6b1273d3dafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9555555555555556,\n",
       " 0.9444444444444444,\n",
       " 0.9555555555555556]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_f1 = []\n",
    "\n",
    "for i in range(len(nivel_profundidad)):\n",
    "    modelo, f1 = Bosque.RegresionBosque(X, y, num_arboles[i], nivel_profundidad[i])\n",
    "    resultados_f1.append(f1)\n",
    "\n",
    "resultados_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "45af10ca-3386-49a1-918e-2488d911ffbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  2],\n",
       "       [14,  2],\n",
       "       [43,  6],\n",
       "       [ 8,  4],\n",
       "       [48,  8]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arboles_v = num_arboles.reshape([-1, 1])\n",
    "profundidad_v = nivel_profundidad.reshape([-1, 1])\n",
    "\n",
    "X_hiperparametros = np.hstack((arboles_v, profundidad_v))\n",
    "X_hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "de00bcfe-9350-4954-80f6-1ea060276da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 1.0 * RBF(length_scale=1)\n",
    "modelo_gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10).fit(X_hiperparametros, resultados_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c149ac99-6f0b-4e44-923f-f7ce9ce3747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = np.linspace(0, 50, 100).reshape([-1, 1])\n",
    "x_2 = np.linspace(2, 10, 100).reshape([-1, 1])\n",
    "m_matricial = np.hstack((x_1, x_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "766ed3ee-b306-4cb3-884f-640deaf22bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_y, desviacionstd_y = modelo_gp.predict(m_matricial, return_std=True)\n",
    "prediccion_y_alto = prediccion_y + 1.96 * desviacionstd_y\n",
    "i_prox = np.argmax(prediccion_y_alto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ba4f4f8e-340b-4f51-a340-919bde7a3a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33.        ,  2.        ],\n",
       "       [14.        ,  2.        ],\n",
       "       [43.        ,  6.        ],\n",
       "       [ 8.        ,  4.        ],\n",
       "       [48.        ,  8.        ],\n",
       "       [31.31313131,  7.01010101]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nueva_X = np.vstack((X_hiperparametros, m_matricial[i_prox]))\n",
    "nueva_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0b1bb799-08ed-4161-83d3-819d6189f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "padi = m_matricial[i_prox]\n",
    "padi\n",
    "#Si estos dos no se ponen como enteros me marca un error\n",
    "padi_0 = int(padi[0])\n",
    "padi_1 = int(padi[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "523028cf-90ca-42cd-94ae-2d425b7d0bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9555555555555556,\n",
       " 0.9444444444444444,\n",
       " 0.9555555555555556,\n",
       " 0.9444444444444444]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo, f1 = Bosque.RegresionBosque(X, y, (padi_0), (padi_1))\n",
    "resultados_f1.append(f1)\n",
    "resultados_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "abd5417c-e11a-400d-bc87-fd40342cd533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 2:\n",
      "[0.9333333333333333, 0.9333333333333333, 0.9555555555555556, 0.9444444444444444, 0.9555555555555556, 0.9444444444444444, 0.9555555555555556]\n"
     ]
    }
   ],
   "source": [
    "# Segunda iteración \n",
    "kernel = 1.0 * RBF(length_scale=1)\n",
    "modelo_gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10).fit(nueva_X, resultados_f1)\n",
    "\n",
    "prediccion_y, desviacionstd_y = modelo_gp.predict(m_matricial, return_std=True)\n",
    "prediccion_y_alto = prediccion_y + 1.96 * desviacionstd_y\n",
    "i_prox = np.argmax(prediccion_y_alto)\n",
    "\n",
    "padi = m_matricial[i_prox]\n",
    "nueva_X2 = np.vstack((nueva_X, padi))\n",
    "\n",
    "modelo, f1 = Bosque.RegresionBosque(X, y, 46, 9) \n",
    "resultados_f1.append(f1)\n",
    "\n",
    "\n",
    "print(\"Iteración 2:\")\n",
    "print(resultados_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a6e7506e-43d0-4fe1-9078-69dab02fb548",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6, 7]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[148], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Tercera iteración \u001b[39;00m\n\u001b[0;32m      2\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m RBF(length_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m modelo_gp \u001b[38;5;241m=\u001b[39m GaussianProcessRegressor(kernel\u001b[38;5;241m=\u001b[39mkernel, n_restarts_optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(nueva_X, resultados_f1)\n\u001b[0;32m      5\u001b[0m prediccion_y, desviacionstd_y \u001b[38;5;241m=\u001b[39m modelo_gp\u001b[38;5;241m.\u001b[39mpredict(m_matricial, return_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m prediccion_y_alto \u001b[38;5;241m=\u001b[39m prediccion_y \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.96\u001b[39m \u001b[38;5;241m*\u001b[39m desviacionstd_y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:251\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m     dtype, ensure_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    252\u001b[0m     X,\n\u001b[0;32m    253\u001b[0m     y,\n\u001b[0;32m    254\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    255\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    256\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    257\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    260\u001b[0m n_targets_seen \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m n_targets_seen \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1281\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1264\u001b[0m     X,\n\u001b[0;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1277\u001b[0m )\n\u001b[0;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1281\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6, 7]"
     ]
    }
   ],
   "source": [
    "# Tercera iteración \n",
    "kernel = 1.0 * RBF(length_scale=1)\n",
    "modelo_gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10).fit(nueva_X, resultados_f1)\n",
    "\n",
    "prediccion_y, desviacionstd_y = modelo_gp.predict(m_matricial, return_std=True)\n",
    "prediccion_y_alto = prediccion_y + 1.96 * desviacionstd_y\n",
    "i_prox = np.argmax(prediccion_y_alto)\n",
    "\n",
    "padi = m_matricial[i_prox]\n",
    "nueva_X3 = np.vstack((nueva_X2, padi))\n",
    "\n",
    "modelo, f1 = Bosque.RegresionBosque(X, y, 41, 8)  \n",
    "resultados_f1.append(f1)\n",
    "\n",
    "print(\"Iteración 3:\")\n",
    "print(resultados_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66df871-47ba-4c7f-a7c1-00d0982f19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuarta iteración \n",
    "kernel = 1.0 * RBF(length_scale=1)\n",
    "modelo_gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10).fit(nueva_X, resultados_f1)\n",
    "\n",
    "prediccion_y, desviacionstd_y = modelo_gp.predict(m_matricial, return_std=True)\n",
    "prediccion_y_alto = prediccion_y + 1.96 * desviacionstd_y\n",
    "i_prox = np.argmax(prediccion_y_alto)\n",
    "\n",
    "padi = m_matricial[i_prox]\n",
    "nueva_X4 = np.vstack((nueva_X3, padi))\n",
    "\n",
    "modelo, f1 = Bosque.RegresionBosque(X, y, 36, 7)  \n",
    "resultados_f1.append(f1)\n",
    "\n",
    "print(\"Iteración 4:\")\n",
    "print(resultados_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4448a5ad-c97f-4961-a320-46fcdfcde660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quinta iteración \n",
    "kernel = 1.0 * RBF(length_scale=1)\n",
    "modelo_gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10).fit(nueva_X, resultados_f1)\n",
    "\n",
    "prediccion_y, desviacionstd_y = modelo_gp.predict(m_matricial, return_std=True)\n",
    "prediccion_y_alto = prediccion_y + 1.96 * desviacionstd_y\n",
    "i_prox = np.argmax(prediccion_y_alto)\n",
    "\n",
    "padi = m_matricial[i_prox]\n",
    "nueva_X5 = np.vstack((nueva_X4, padi))\n",
    "\n",
    "modelo, f1 = Bosque.RegresionBosque(X, y, 31, 6) \n",
    "resultados_f1.append(f1)\n",
    "\n",
    "print(\"Iteración 5:\")\n",
    "print(resultados_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899aceaf-3bf5-495e-bc1e-c4a3bbd532b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sexta iteración \n",
    "kernel = 1.0 * RBF(length_scale=1)\n",
    "modelo_gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10).fit(nueva_X, resultados_f1)\n",
    "\n",
    "prediccion_y, desviacionstd_y = modelo_gp.predict(m_matricial, return_std=True)\n",
    "prediccion_y_alto = prediccion_y + 1.96 * desviacionstd_y\n",
    "i_prox = np.argmax(prediccion_y_alto)\n",
    "\n",
    "padi = m_matricial[i_prox]\n",
    "nueva_X5 = np.vstack((nueva_X4, padi))\n",
    "\n",
    "modelo, f1 = Bosque.RegresionBosque(X, y, 26, 5)  \n",
    "resultados_f1.append(f1)\n",
    "\n",
    "print(\"Iteración 6:\")\n",
    "print(resultados_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e083a3c-fa68-4942-b5d3-f1f7130b4fbb",
   "metadata": {},
   "source": [
    "### Actividad 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817a47c-0081-4376-b222-c65735f4ab9d",
   "metadata": {},
   "source": [
    "Inicializa 2 vectores con posibles valores para las variables independientes:\n",
    "- árboles: números enteros entre 5 y 50\n",
    "- profundidad: números enteros entre 2 y 10\n",
    "\n",
    "Utiliza el algoritmo de Simulated Annealing que siga el siguiente orden:\n",
    "- Elige un punto de partida para las variables.\n",
    "- Selecciona al azar una de las dos para modificarlas.\n",
    "- Selecciona un elemento al azar de la lista que contiene los posibles valores de esa variable.\n",
    "- Sigue el algoritmo ($p$ y $q$) para decidir si usas esa combinación nueva o si mantienes la anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e6286fe8-ec56-4871-9c31-8d4d3ca4c0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "v_arboles = np.arange(5, 51)  # Valores para árboles\n",
    "v_profundidad = np.arange(2, 11)  # Valores para profundidad\n",
    "\n",
    "T = 10\n",
    "T_min = 0.1\n",
    "alpha = 0.9\n",
    "\n",
    "arbol_actual = random.choice(v_arboles)\n",
    "profundidad_actual = random.choice(v_profundidad)\n",
    "modelo, f1_actual = Bosque.RegresionBosque(X, y, arbol_actual, profundidad_actual)\n",
    "\n",
    "mejor_f1 = f1_actual\n",
    "mejores_hiperparametros = (arbol_actual, profundidad_actual)\n",
    "\n",
    "while T > T_min:\n",
    "    if random.choice([True, False]):\n",
    "        nuevo_arbol = random.choice(v_arboles)\n",
    "        nueva_profundidad = profundidad_actual\n",
    "    else:\n",
    "        nuevo_arbol = arbol_actual\n",
    "        nueva_profundidad = random.choice(v_profundidad)\n",
    "\n",
    "    modelo, nuevo_f1 = Bosque.RegresionBosque(X, y, nuevo_arbol, nueva_profundidad)\n",
    "\n",
    "    p = np.exp((nuevo_f1 - f1_actual) / T)\n",
    "    if nuevo_f1 > f1_actual or random.random() < p:\n",
    "        arbol_actual = nuevo_arbol\n",
    "        profundidad_actual = nueva_profundidad\n",
    "        f1_actual = nuevo_f1\n",
    "\n",
    "    if f1_actual > mejor_f1:\n",
    "        mejor_f1 = f1_actual\n",
    "        mejores_hiperparametros = (arbol_actual, profundidad_actual)\n",
    "\n",
    "    T = T * alpha\n",
    "\n",
    "mejor_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239fa243-bd6d-4ec4-860a-2eae65cea710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00442559-60d2-440a-9ba0-5217ea775ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
